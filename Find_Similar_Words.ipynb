{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries and Downloading Glove 6B"
      ],
      "metadata": {
        "id": "Su_Z6GMoOKlk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HV-XfKcXwQEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "226d4948-e0f4-4013-eb2b-ba58e81a12da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-25 17:25:33--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-02-25 17:25:33--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-02-25 17:25:33--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2024-02-25 17:28:12 (5.19 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "Collecting coremltools\n",
            "  Downloading coremltools-7.1-cp310-none-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from coremltools) (1.25.2)\n",
            "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from coremltools) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from coremltools) (1.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from coremltools) (4.66.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from coremltools) (23.2)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from coremltools) (23.2.0)\n",
            "Collecting cattrs (from coremltools)\n",
            "  Downloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyaml (from coremltools)\n",
            "  Downloading pyaml-23.12.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs->coremltools) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs->coremltools) (4.9.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml->coremltools) (6.0.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->coremltools) (1.3.0)\n",
            "Installing collected packages: pyaml, cattrs, coremltools\n",
            "Successfully installed cattrs-23.2.3 coremltools-7.1 pyaml-23.12.0\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "!pip install coremltools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xJYqOoVBwVga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f684941a-eb97-4b59-c29e-b0cc644355c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:coremltools:scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
            "WARNING:coremltools:XGBoost version 2.0.3 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n",
            "WARNING:coremltools:TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import coremltools as ct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kItgCwvZwTxw"
      },
      "outputs": [],
      "source": [
        "embedding_index = {}\n",
        "with open('glove.6B.50d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = np.array(coefs).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine Similarity Calculation Implementation\n"
      ],
      "metadata": {
        "id": "fCYx33hXOuJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "word_list = embedding_index.keys()\n",
        "word2index = {word: index for index, word in enumerate(word_list)}\n",
        "index2word = {index: word for word, index in word2index.items()}"
      ],
      "metadata": {
        "id": "yqqcAEh0iGmN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2index['eat']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hma9-nuETCjV",
        "outputId": "27cdb205-ebbf-4a7a-e7d1-b2533f017df7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3623"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(embedding_index.keys())\n",
        "embeddings_matrix = np.array([embedding_index[word] for word in words])\n",
        "embeddings_matrix = embeddings_matrix / np.linalg.norm(embeddings_matrix, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "wbs5NMvRpxWr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_word = \"eat\""
      ],
      "metadata": {
        "id": "LclH2ZMvOVC3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_of_word = word2index[input_word]\n",
        "\n",
        "target_vector = embeddings_matrix[index_of_word]\n",
        "target_vector = target_vector / np.linalg.norm(target_vector)\n",
        "similarities = np.dot(embeddings_matrix, target_vector)\n",
        "self_index = words.index(input_word)\n",
        "similarities[self_index] = -np.inf\n",
        "closest_word_index = np.argmax(similarities)\n",
        "\n",
        "\n",
        "closest_word = words[closest_word_index]\n",
        "print(closest_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBlXAQx7MzhV",
        "outputId": "48dc0605-d394-4610-b2fc-e87aec09a1be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_of_word = tf.keras.Input(shape=(1,))\n",
        "index_e3 = index_of_word[1]\n",
        "index_e3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7Tdm7dhHm2d",
        "outputId": "9affc946-7a5a-4d1e-b977-4a2c54b1ff7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(1,) dtype=float32 (created by layer 'tf.__operators__.getitem')>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a TensorFlow model"
      ],
      "metadata": {
        "id": "z1SWcscMQPnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class ClosestWordIndexLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, embeddings_matrix, words, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embeddings_matrix = tf.constant(embeddings_matrix, dtype=tf.float32)\n",
        "        self.words = words\n",
        "\n",
        "    def call(self, input_word_index):\n",
        "        input_word_vector = tf.nn.embedding_lookup(self.embeddings_matrix, input_word_index)\n",
        "        input_word_vector = tf.math.l2_normalize(input_word_vector, axis=-1)\n",
        "\n",
        "        similarities = tf.matmul(self.embeddings_matrix, input_word_vector, transpose_b=True)\n",
        "        similarities = tf.reshape(similarities, [-1])\n",
        "\n",
        "        self_mask = tf.one_hot(input_word_index, depth=tf.shape(self.embeddings_matrix)[0], on_value=-np.inf, off_value=0.0, dtype=tf.float32)\n",
        "        similarities += self_mask\n",
        "        return similarities\n",
        "\n",
        "# Usage in a model\n",
        "def create_model(embeddings_matrix, words):\n",
        "    input_word_index = tf.keras.Input(shape=(), dtype=tf.int32)\n",
        "    res = ClosestWordIndexLayer(embeddings_matrix, words)(input_word_index)\n",
        "    model = tf.keras.Model(inputs=input_word_index, outputs=res)\n",
        "    return model\n",
        "\n",
        "model = create_model(embeddings_matrix, words)\n"
      ],
      "metadata": {
        "id": "pLj9c0S8G6t-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(np.array([3623]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10T47cQTKvqH",
        "outputId": "c2fa35c2-72ec-462b-a960-303994530e2f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 400000), dtype=float32, numpy=\n",
              "array([[ 0.3161376 ,  0.42795926,  0.4791656 , ..., -0.01428229,\n",
              "        -0.17280248, -0.60417926]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert the TensorFlow model to a CoreML model\n",
        "\n"
      ],
      "metadata": {
        "id": "WUuG4J05Ev1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iOS_find_word = ct.convert(\n",
        "    model,\n",
        "    source=\"tensorflow\",\n",
        "    inputs=[ct.TensorType(name=\"input_2\", dtype=np.int32, shape=(1,))],\n",
        "    outputs=[ct.TensorType(name=\"Identity\", dtype=np.float32)],\n",
        "    minimum_deployment_target=ct.target.macOS13\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxozwCSKrbpk",
        "outputId": "413b1d2c-7bea-45a9-dd72-205a65cd0d65"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running TensorFlow Graph Passes: 100%|██████████| 6/6 [00:01<00:00,  3.62 passes/s]\n",
            "Converting TF Frontend ==> MIL Ops: 100%|██████████| 20/20 [00:00<00:00, 1572.20 ops/s]\n",
            "Running MIL frontend_tensorflow2 pipeline: 100%|██████████| 7/7 [00:00<00:00, 3209.11 passes/s]\n",
            "Running MIL default pipeline: 100%|██████████| 71/71 [00:01<00:00, 51.62 passes/s]\n",
            "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 3278.93 passes/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iOS_find_word.save('iOS_find_wordV2.mlpackage')"
      ],
      "metadata": {
        "id": "eulj5lIFsB6y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/iOS_find_wordV2.mlpackage.zip /content/iOS_find_wordV2.mlpackage"
      ],
      "metadata": {
        "id": "HKyEMtmlsoIl",
        "outputId": "3da011ad-fed8-4659-e374-3b2b1f073ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/iOS_find_wordV2.mlpackage/ (stored 0%)\n",
            "  adding: content/iOS_find_wordV2.mlpackage/Manifest.json (deflated 60%)\n",
            "  adding: content/iOS_find_wordV2.mlpackage/Data/ (stored 0%)\n",
            "  adding: content/iOS_find_wordV2.mlpackage/Data/com.apple.CoreML/ (stored 0%)\n",
            "  adding: content/iOS_find_wordV2.mlpackage/Data/com.apple.CoreML/model.mlmodel (deflated 78%)\n",
            "  adding: content/iOS_find_wordV2.mlpackage/Data/com.apple.CoreML/weights/ (stored 0%)\n",
            "  adding: content/iOS_find_wordV2.mlpackage/Data/com.apple.CoreML/weights/weight.bin (deflated 8%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Su_Z6GMoOKlk",
        "fCYx33hXOuJa",
        "z1SWcscMQPnT",
        "WUuG4J05Ev1k"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}